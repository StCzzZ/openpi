"""
Script for converting h5py dataset (from run_parallel_with_hil.py) to LeRobot format.

This script reads the h5py file generated by run_parallel_with_hil.py and converts it
to the LeRobot dataset format that can be used for training robot learning models.

H5py file structure:
    - actions: (total_steps, 7) - action data
    - episode_lengths: (num_episodes,) - cumulative start indices for each episode
    - task_descriptions: (num_episodes,) - task description for each episode
    - obs/states: (total_steps, state_dim) - state observations
    - obs/image: (total_steps, H, W, 3) - agentview images
    - obs/wrist_image: (total_steps, H, W, 3) - wrist camera images

Usage:
    python examples/libero/convert_h5py_libero_to_lerobot.py --h5_file_path /path/to/trajectories_task.h5 --output_repo_name my_dataset
    
    # To push to Hugging Face Hub:
    python examples/libero/convert_h5py_libero_to_lerobot.py --h5_file_path /path/to/trajectories_task.h5 --output_repo_name my_dataset --push_to_hub

    sudo uv run python examples/libero/convert_h5py_libero_to_lerobot.py --h5_file_path data/libero/h5py_records/libero_spatial_id3.h5 --output_repo_root_tmp data_tmp/libero/libero_spatial_h20_test --output_repo_id 0 --output_repo_root_final data/libero/libero_spatial_h20_test 

Note: You need to install lerobot first:
    pip install lerobot
"""

import shutil
import pathlib
import h5py
import numpy as np
import tyro
from termcolor import cprint
from typing import Optional
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from lerobot.common.datasets.lerobot_dataset import HF_LEROBOT_HOME
import os


def convert_h5py_to_lerobot(
    h5_file_path: str,
    output_repo_root_tmp: str = "data_tmp/libero/hil_traj_lerobot",
    output_repo_root_final: str = "data/libero/hil_traj_lerobot",
    output_repo_id: str = '0',
    *,
    fps: int = 10,
    robot_type: str = "panda",
    push_to_hub: bool = False,
    hub_tags: Optional[list] = None,
    license: str = "apache-2.0",
    private: bool = False,
    image_writer_threads: int = 10,
    image_writer_processes: int = 5,
):
    """
    Convert h5py dataset to LeRobot format.
    
    Args:
        h5_file_path: Path to the h5py file generated by run_parallel_with_hil.py
        output_repo_name: Name for the output dataset (also used for HuggingFace Hub)
        fps: Frames per second of the dataset
        robot_type: Type of robot (e.g., "panda" for Franka Panda)
        push_to_hub: Whether to push the dataset to HuggingFace Hub
        hub_tags: Tags for the HuggingFace Hub (default: ["libero", "panda", "human-in-the-loop"])
        license: License for the dataset
        private: Whether the HuggingFace Hub repo should be private
        image_writer_threads: Number of threads for writing images
        image_writer_processes: Number of processes for writing images
    """
    
    # Set default tags if not provided
    if hub_tags is None:
        hub_tags = ["libero", "panda", "human-in-the-loop"]
    
    # Verify h5py file exists
    h5_path = pathlib.Path(h5_file_path)
    if not h5_path.exists():
        raise FileNotFoundError(f"H5py file not found: {h5_file_path}")
    
    cprint(f"Loading h5py file from: {h5_file_path}", "cyan")
    
    # Open h5py file and inspect structure
    with h5py.File(h5_file_path, "r") as h5_file:
        # Print dataset structure for debugging
        cprint("H5py file structure:", "yellow")
        cprint(f"  Keys: {list(h5_file.keys())}", "yellow")
        if "obs" in h5_file:
            cprint(f"  obs/ keys: {list(h5_file['obs'].keys())}", "yellow")
        
        # Load metadata
        actions = h5_file["actions"][:]
        episode_lengths = h5_file["episode_lengths"][:]
        task_descriptions = h5_file["task_descriptions"][:]
        states = h5_file["obs/states"][:]
        images = h5_file["obs/image"][:]
        wrist_images = h5_file["obs/wrist_image"][:]
        
        # Get dimensions
        state_dim = states.shape[1]
        image_height, image_width = images.shape[1], images.shape[2]
        action_dim = actions.shape[1]
        num_episodes = len(episode_lengths) - 1
        
        cprint(f"episode_lengths: {episode_lengths}", "green")
        cprint(f"\nDataset information:", "green")
        cprint(f"  Total timesteps: {len(actions)}", "green")
        cprint(f"  Number of episodes: {num_episodes}", "green")
        cprint(f"  State dimension: ({states.shape[0]}, {state_dim})", "green")
        cprint(f"  Action dimension: ({actions.shape[0]}, {action_dim})", "green")
        cprint(f"  Image size: ({images.shape[0]}, {image_height}x{image_width})", "green")
        
        # Clean up any existing dataset in the output directory
        ## We save the dataset in the default dir (~/.cache/huggingface/lerobot_datasets/), and move it to the final path to make the process faster. ##
        output_path_tmp = pathlib.Path(output_repo_root_tmp)
        output_path_final = pathlib.Path(output_repo_root_final)
        cprint(f"save dataset to temparory dir: {output_path_tmp}", "green")
        if output_path_tmp.exists():
            cprint(f"Output path {output_path_tmp} already exists. It will be removed.", "yellow")
            shutil.rmtree(output_path_tmp)

        # output_root = str(pathlib.Path(output_repo_root))
        # repo_id = pathlib.Path(output_repo_id)
        # cprint(f"output_root: {output_root}, repo_id: {repo_id}", "green")
        # cprint(f"\nCreating LeRobot dataset: {output_root}/{repo_id}", "cyan")
        
        # Create LeRobot dataset with appropriate features
        ### MODIFICATIOIN: turn "repo_id" into "root" ###
        
        dataset = LeRobotDataset.create(
            root=output_path_tmp,
            repo_id=output_repo_id,
            robot_type=robot_type,
            fps=fps,
            features={
                "image": {
                    "dtype": "image",
                    "shape": (image_height, image_width, 3),
                    "names": ["height", "width", "channel"],
                },
                "wrist_image": {
                    "dtype": "image",
                    "shape": (image_height, image_width, 3),
                    "names": ["height", "width", "channel"],
                },
                "state": {
                    "dtype": "float32",
                    "shape": (state_dim,),
                    "names": ["state"],
                },
                "actions": {
                    "dtype": "float32",
                    "shape": (action_dim,),
                    "names": ["actions"],
                },
            },
            image_writer_threads=image_writer_threads,
            image_writer_processes=image_writer_processes,
        )
        
        # Process each episode
        cprint(f"\nConverting episodes to LeRobot format...", "cyan")
        for episode_idx in range(num_episodes):
            # Get start and end indices for this episode
            start_idx = int(episode_lengths[episode_idx])
            end_idx = int(episode_lengths[episode_idx + 1])
            
            # Skip if episode is empty
            if start_idx >= end_idx:
                cprint(f"  Skipping empty episode {episode_idx}", "yellow")
                continue
            
            episode_length = end_idx - start_idx
            task_description = task_descriptions[episode_idx].decode() if isinstance(task_descriptions[episode_idx], bytes) else task_descriptions[episode_idx]
            
            cprint(f"  Processing episode {episode_idx + 1}/{num_episodes} (length: {episode_length}, task: {task_description})", "blue")
            
            # Extract episode data
            episode_actions = actions[start_idx:end_idx]
            episode_states = states[start_idx:end_idx]
            episode_images = images[start_idx:end_idx]
            episode_wrist_images = wrist_images[start_idx:end_idx]
            
            # Add each frame to the dataset
            for step_idx in range(episode_length):
                dataset.add_frame(
                    {
                        "image": episode_images[step_idx],
                        "wrist_image": episode_wrist_images[step_idx],
                        "state": episode_states[step_idx].astype(np.float32),
                        "actions": episode_actions[step_idx].astype(np.float32),
                        "task": task_description,
                    }
                )
            
            # Save the episode
            dataset.save_episode()
            cprint(f"    Episode {episode_idx + 1} saved successfully", "green")
    
    cprint(f"\n✓ Dataset conversion completed!", "green")
    cprint(f"  Total episodes converted: {num_episodes}", "green")
    cprint(f"moving dataset to: {output_path_final}", "green")
    if os.path.exists(output_path_final):
        shutil.rmtree(output_path_final)
        cprint(f"  Removed existing directory: {output_path_final}", "yellow")
    shutil.move(str(output_path_tmp), str(output_path_final))

    # cprint(f"  Dataset saved to: {output_repo_name}", "green")
    
    # Optionally push to the Hugging Face Hub
    if push_to_hub:
        cprint(f"\nPushing dataset to Hugging Face Hub...", "cyan")
        dataset.push_to_hub(
            tags=hub_tags,
            private=private,
            push_videos=True,
            license=license,
        )
        cprint(f"✓ Dataset pushed to Hub successfully!", "green")


def main(
    h5_file_path: str,
    output_repo_root_tmp: str = "data_tmp/hil_trajectories",
    output_repo_root_final: str = "data/hil_trajectories",
    output_repo_id: str = '0',
    fps: int = 10,
    robot_type: str = "panda",
    push_to_hub: bool = False,
    private: bool = False,
    image_writer_threads: int = 10,
    image_writer_processes: int = 5,
):
    """
    Main function to convert h5py dataset to LeRobot format.
    
    Args:
        h5_file_path: Path to the h5py file (e.g., "data/libero/h5py_records/trajectories_task.h5")
        output_repo_name: Name for the output dataset (default: "data/hil_trajectories")
        fps: Frames per second of the dataset (default: 10)
        robot_type: Type of robot (default: "panda")
        push_to_hub: Whether to push the dataset to HuggingFace Hub (default: False)
        private: Whether the HuggingFace Hub repo should be private (default: False)
        image_writer_threads: Number of threads for writing images (default: 10)
        image_writer_processes: Number of processes for writing images (default: 5)
    """
    
    convert_h5py_to_lerobot(
        h5_file_path=h5_file_path,
        output_repo_root_tmp=output_repo_root_tmp,
        output_repo_root_final=output_repo_root_final,
        output_repo_id=output_repo_id,
        fps=fps,
        robot_type=robot_type,
        push_to_hub=push_to_hub,
        private=private,
        image_writer_threads=image_writer_threads,
        image_writer_processes=image_writer_processes,
    )


if __name__ == "__main__":
    tyro.cli(main)
